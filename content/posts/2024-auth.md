---
title: Alice and Bob in wonderland
subtitle: Bootstrapping identity and authority in a world without servers

description: |
  We know how software security works when you have a server to log people in and enforce permissions. 
  When you take the server away, though, things that you thought were straightforward become weird, 
  seemingly circular and anchored in thin air. If you're building a distributed application, 
  how do you establish trust on a solid footing?

date: '2024-05-28'
slug: local-first-auth
draft: false

caption: '"It would be so nice if something made sense for a change.‚Äù <i>‚Äî Lewis Carroll, Alice in Wonderland</i>'
tags: software
---

About four years ago, I first started thinking about authentication and authorization in a
local-first context. In was initially weird and confusing, like I'd stepped through the
looking-glass, and I found myself wrestling with big philosophical questions like "where does
authority _ultimately_ come from?" and "what does it mean to _know_ someone?".

I'm going to walk you through my journey, from with that initial disorientation to what I believe
are solid, principled answers to these questions, in the course of developing the <a
href='https://github.com/local-first-web/auth'>@localfirst/auth</a> library.

### Why this is weird and confusing

It might not be obvious why I would find this disorienting, so I'll explain.

Traditional authentication and authorization ultimately "root out" in a physical piece of hardware,
owned and controlled by a company that you've decided to trust. The hardware is a server that has
your username and password and rules about what you're allowed to do. It might be controlled by your
employer, or a SaaS provider, or a big tech company.

The server is like a guard at the castle gates. If the server doesn't recognize you, it doesn't let
you in. If the server doesn't think you should be allowed to have something, it doesn't give it to
you.

Of course, the whole point of local-first software is that we don't love that arrangement.

But when you take away that central server, you're losing the thing that all our notions of security
are anchored to.

If all you have is clients, who are peers ‚Äî which means they relate to each other as equals ‚Äî then
how do we know who is who? How do we know who to trust? What do permissions even mean: If not a
server, who exactly is "giving permission"?

It's like living in a monarchy and realizing that the king is just another person, and not someone
appointed by God. Just like countries making that transition from monarchy to democracy, we're
suddenly adrift, and have to come up with completely new arrangements to solve problems that were
already solved ‚Äî even if in a suboptimal way.

Without that solid foundation, we're down the rabbit hole.

"Bootstrapping" has become a word that we associate with something as easy and routine as turning
your computer on. But the whole point of bootstrapping as a metaphor is that _it's supposed to be
impossible_: You _can't_ lift yourself up by pulling on your bootstraps.

And without a server, it feels like we're having to pull ourselves up by our bootstraps on some
fundamental questions:

- **What anchors identity?** How do we authenticate with a peer device?
- **What anchors authority?** How do permissions work? Who has the authority to give anyone
  permission anyway?

### The road to localfirst/auth

In 2020, a couple of weeks into the pandemic, I started work on a library that became
localfirst/auth.

I had to learn about modern cryptography starting from zero.

I was immediately fascinated by how _empowering_ public-key cryptography is, in the sense that it
can put me on an equal footing with even very powerful adversaries.

The movies would lead you to believe that defeating encryption is something a dude in a hoodie can
do just by typing with great intensity.

But of course that's not how it really works. Unlike in the movies, strong cryptography can't be
defeated, as long as you didn't screw something up. (And as long as quantum computers haven't been
invented yet.)

> For most cryptographic operations, there exist widely accepted primitives that have been
> extensively studied, and breaking them is considered computationally infeasible on any existing
> computer cluster. ‚Äî Daniel J. Bernstein et al. (2012)

The point is you don't need a lot of money, or computing power, or specialized equipment. Strong
encryption doesn't cost any more than weak encryption. It doesn't cost any more to use a long
encryption key than a short one. It's just math. It's just code. And not even that much code ‚Äî the
entire NaCl cryptographic codebase fits in 100 tweets (that's the original 256-character tweets).

## With no servers, what anchors _identity_?

So anyway I'm sitting down to work on this, and the first thing that makes my head spin is, how do
you know you're talking to?

When we collaborate or communicate online using a traditional cloud-based platform, we can think of
the service provider as **vouching for us** ‚Äî introducing us to other people and confirming our
identity.

- If I'm using Slack to talk to you, you know it's me because Slack vouched for me, and you trust
  Slack.

- (And Slack knows it's me because I logged in using OAuth, so Google vouched for me, and Slack
  trusts Google.)

- If I'm using iMessage, you know it's me because Apple vouched for me, and you trust Apple.

- If I comment on your pull request, you know it's me because GitHub vouched for me, and you trust
  GitHub.

If we don't want to put our trust in a centralized third party, then who will vouch us?
In a system where everyone's a peer, then presumably peers will have to vouch for peers, in
some kind of chain of trust. But that chain has to be anchored somewhere: Maybe Charlie vouches
for Bob to Alice, but who vouches for Charlie?

Ignoring the infinite regress problem for the moment, it seems clear that the solution will be
**something something public-key cryptography**. But to do public-key cryptography, you need to know
people's public keys.

> "Crypto is a tool for turning a whole swathe of problems into key management problems. Key
> management problems are way harder than virtually all cryptographers think.‚Äù

I find this quote encouraging. Dr Kissner was the head of information security at Twitter and I
don't think they meant this tweet to be encouraging.

But even granting that key management is a hard problem, the idea that you can collapse lots of
different problems into this one problem is exciting, because you just have to focus on solving that
thing. If you can succeed at the key management thing then you can solve this "whole swathe of
problems.‚Äù

So how do we learn people's public keys?

The most obvious solution is to have some trusted party keep a directory of people and their public
keys, and of course that‚Äôs totally a thing that exists. The certificate authorities (CAs) that make
secure https connections possible are an example. Some big companies have their own certificate
authorities to anchor their employees' digital identities. And countries can do the same for
residents. Here in Spain, I can obtain a certificate from the treasury department to install in my
browser, which allows me to transparently authenticate to government websites and sign official
documents digitally.

But we‚Äôre trying to do this without depending on centralized services.

If you want a decentralized solution, the alternative seems to be for people to actively share their
own keys directly with each other.

This was the approach taken by PGP (‚ÄúPretty Good Privacy‚Äù) in the 1990s. PGP was the first
encryption toolset intended for ordinary users. The idea was that people would put their public keys
on their websites and in their email signatures. Apparently there were key signing parties where
people exchanged and signed each other‚Äôs keys.

From the looks of it these parties were a really super fun way to spend a saturday night and I can't
imagine why but this didn't take the planet by storm. üòÜüòÖ.

Keybase had a cool idea which was: You put your public keys on public sites like Twitter or GitHub,
and then anyone can look up a person‚Äôs public keys by username. Unfortunately, this also failed to
capture the imagination of the non-nerd public; but we'll come back to Keybase.

The first applications to truly bring end-to-end encryption to the masses were messaging apps. The
Signal protocol came out in 2013, and two years later WhatsApp brought it to their entire customer
base, and overnight about a billion people were using encrypted messaging. Since then WhatsApp's
user base grew to two billion and then to three billion, making it one of the most widely used
communication tools in all of human history.

This succeeded because they made encryption transparent to the user. The key insight is that a
public key will never be like an email or a telephone number. It's not a stable component of our
digital identity. Wrangling encryption keys is a job for computers, not for people. Devies should
just generate keys as needed and we should never see them or have to think about them. Private keys
should never leave the device, and public keys should be shared automatically with other devices.

|                                 | ![]($$/drake-no.jpg)     | ![]($$/drake-yes.jpg)           |
| ------------------------------- | ------------------------ | ------------------------------- |
|                                 | PGP, Keybase, arrow      | signal whatsapp telegram        |
| **what** is the scope of a key? | one human identity       | one app on one device           |
| **who** manages keys?           | humans                   | computers                       |
| **when** do we see our keys?    | often                    | never                           |
| **how** are keys shared         | manually, human to human | automatically, device to device |

We're agreed, then, that device-to-device sharing of keys is better than key signing parties. But
Alice's device still needs to know that Bob's device is really Bob's device, and not Eve's device
pretending to be Bob's device.

WhatsApp and Signal take an approach called "Trust On First Use", or TOFU. Here's how that works:

Alice's device invites Bob's device to communicate, and trusts that the first device to show up is,
in fact, Bob's device. There's a little risk there, they're both taking a little leap of faith, but
it's probably fine. The two devices exchange their public keys on that initial connection. From that
point on they can use those keys to authenticate and encrypt messages to each other.

That seems reasonable.

But here's the problem: We've been saying "device" and that doesn't actually capture the reality.
It's a different device if you open the app in a different browser. It's a new device if you reset
your phone, reformat your computer, or reinstall the application. And then you have to take a chance
on TOFU again.

This is called an "account reset", and in theory when this happens you should do a manual
verification process. When a user has an account reset, the messaging apps suggest to everyone they
communicate with that they compare "security codes" or "safety numbers". Most users don't do this -
I never have, I can't imagine that people less technical than me do this. And anyway this is bad
enough for a single pairwise connection; where this all really falls apart is in a large group,
where the number of pairwise connections scales exponentially with the size of the group.

So when you want to connect with someone and don't know their public key, is there an alternative to
TOFU for securing that initial connection?

The most promising approach is to first share a single-use password out of band (in person, or via a
channel you already trust).

We're saying "password" but it's generally presented as an invitation code.

In the most common forms, both parties need to know the secret code; this is called a balanced PAKE.

The downside is that the inviter and invitee need to connect directly to validate the invitation.

With an asymmetric PAKE (asymmetric because the verifier doesn't need to know the password) a third
party can validate an invitation code without knowing it in advance or asking for it.

We talked about Keybase and the "social key" thing. They decide to try to monetize by building a
Slack-but-encrypted thing for enterprise customers. They quickly realized that even if the global
nerd population thought the idea of putting your public key on Twitter was really cool, Jim in
Accounts Payable is probably just not going to do that. Sorry, it's just not going to happen.

So they needed a way to bootstrap that initial key exchange, and they proposed something called a
Seitan Token Exchange (presumably "seitan" because it's not as soft as tofu).

This is the approach I stole for localfirst/auth. At the time I didn't know a PAKE from a hole in
the ground, but as it turns out this is essentially an asymmetric PAKE.

This is how it works:

- Alice creates an arbitrary password
- Alice invites Bob by giving him the password
- Alice derives a signature keypair from password
- Alice gives Charlie the public key
- Bob derives the same signature keypair from password
- Bob generates a proof by signing something with the private key
- Bob shows Charlie the proof
- Charlie validates the proof with the public key
- Charlie now knows that Bob is the person Alice invited
- Bob and Charlie can now exchange public keys; Charlie can then pass on Alice and Charlie's public
  keys to each other

As a side note, we've been talking about "identity"; but the beauty of this approach is that
identity doesn't need to mean "who you are in the world", in the sense of linking to your real name
or email or whatever ‚Äî it can just mean "who you are _to me_".

For example, in Ink & Switch's Backchannel project one of the motivating use cases was connecting an
anonymous source to a journalist. With a system like this the source doesn't have to have a name at
all; the only thing that matters is that they're able to interact once

Trust and identity are ultimately rooted in real-world relationships and interactions between human
beings. I know you because we interact, whether that's face-to-face or online. **That's what it
means to "know" someone.** And we can use that interaction to bootstrap cryptographically secure
connections going forward. And if you have those secure connections with other people and I trust
you, I can benefit from your connections, and so on, forming a network of trust relationships.

So hat's the answer to our question: What anchors identity? Real-world human **interactions** and
**relationships**.

This feels very natural, human-scale, and rooted in social reality.

The server-centric model roots our identity in getting distant corporations to vouch for us. Are you
really Herb? Yes ‚Äî look, Google vouches for me.

With this model, instead can **we vouch for ourselves**: Are you really Herb? Yes ‚Äî remember we
talked earlier. And we can **vouch for each other**: I have a friend named Herb and this is how you
can recognize him.

## Without servers, what anchors _authority_?

So now I have a way of knowing it's you. But how do I know if you're on my team? How do I know if I
should share this document with you, or if you should be able to edit it?

On a server this information is often recorded in some kind of **access control list** (ACL). So
maybe we need that, but distributed ‚Äî everybody needs a copy of the same list. How would that work?

My first thought was that we could just put this information in an Automerge document and replicate
it across everyone's devices that way. But we can't just let anyone edit this document at will. It
should be obvious if anyone changes the permissions, and we need to know _who_ changed the
permissions, and if they ‚Ä¶ had permission to do so? Do we need an ACL for the ACL?

Let's ignore the infinite regress for the moment and focus on the mechanics. We need a way of
replicating a document that is:

- **tamper-evident:** it shouldn't be possible for someone to surreptitiously modify the list
- **eventually consistent**: everybody should have the same list
- **authenticated**: we need to know who has written changes to the list

So let's look at some options for data structures.

### Hash chain

When we say "tamper-resistant" the first thing you might think of is a hash chain (or
**blockchain**), where each link contains a cryptographic hash of the previous link, so it's
impossible to modify one link or change the order without breaking the chain.

But a blockchain isn't a CRDT ‚Äî doesn't support any concurrency. Replicating it while ensuring
consistency requires enforcing a strict ordering; and cryptocurrency blockchains are famously ‚Ä¶ not
optimized for efficiency.

### Hash graph

To accomplish this without burning enough fossil fuels to power multiple small countries, we could
use a **hash graph**. A hash graph is a hash chain plus branching and conflict resolution. This is
how a CRDT like Automerge supports replication with eventual consistency and automatic conflict
resolution. Git works the same way but with manual conflict resolution.

So far so good. But we still need a way of verifying who made which changes to our distributed
access control list.

### Signature graph

A **signature graph** is a hash graph where the individual operations are signed by the author. This
gives us all three things.

If you look at the work of anyone who's trying to tackle this problem, you're going to see some kind
of signature graph: Matrix, MLS, HALO, UCANs, etc. It's a case of convergent evolution ‚Äî they've all
more or less independently landed on this data structure.

### A group membership CRDT

The way this works, concretely, is that there's a series of operations on the group: It's created,
people are added, people are given authority, people are removed, and so on. And after each
operation we can calculate the state of the group at that point.

The key insight for me was that the root node of the group's signature graph gives you an anchor for
authority. If I create a group, by definition I get to decide who's in it.

The key insight for me was that the root node of a signature graph provides an anchor for authority.
When I create a group, I get to decide who's in it by definition. At the moment of creation, I am
the absolute dictator of a group with no other members. I decide who to add to the group and whether
I want to delegate my authority to other members. I can make everyone else an admin, or even
delegate the right to remove me from the group. Even once I'm gone, the authority behind any
action‚Äîany addition or removal of members, any further delegation of authority‚Äîcan always be traced
back to the authority inherent in my act of creation.

**Detecting and resolving conflicts**

To be replicable, this data structure needs to be a CRDT. However, you can't model group permissions
using a JSON CRDT like Automerge. I'll explain why.

Here we have two concurrent actions, but there's no conflict, and we can resolve this by picking one
or the other in an arbitrary but deterministic order. So far, nothing Automerge couldn't handle.

What if someone takes actions while concurrently being removed? What happens if Bob adds Charlie to
the group and concurrently, Alice removes Bob from the group? Now we have a **conflict**. Is Charlie
in the group or not? It's important to resolve this correctly, or else Bob could circumvent his
removal by writing a concurrent operation adding proxy-Bob to the group.

A: Removals always take precedence. We resolve that conflict by **prioritizing removals**. A generic
CRDT like Automerge won't be able to resolve this conflict in a principled way; it won't even see it
as a conflict. So, we have to build a custom CRDT engine.

### Mutual removals

What if two admins remove each other concurrently? (Or more generally, what if there's a cycle of
concurrent removals?)

As a scenario involving two legitimate members of the group, this is far-fetched and unlikely to
happen. A more realistic and worrying scenario might be, for example, a compromised and revoked
device trying to undo its revocation.

- **Option 1: Remove Both** The logical conclusion of "removals take precedence" is to remove both.
  However, this seems unlikely to be the correct way of resolving the issue. It leaves Charlie
  orphaned in a group without admins and creates an opening for a denial-of-service attack, where a
  rogue device blows up the group rather than allowing itself to be removed.

- **Option 2: Fork the Group** Another approach is to "fork the world" into two parallel versions of
  the same group: one where Alice stays and one where Bob stays. Then each member decides which
  world they want to live in. This reflects the reality of a decentralized system. I call this the
  Papal Schism solution, in honor of the time when there were two popes and all of Catholic
  Christendom had to decide which one to follow.

- **Option 3: Keep the Senior Member** The solution I settled on is to let seniority be a proxy for
  who is more likely to be in the right. In this case, Alice has been in the group longer than Bob,
  so she stays.

## Some conclusions

We started with two big questions about how we find our footings in a local-first world.

**Q:** What anchors identity?

**A:** **Preexisting human relationships and interactions.**

The Seitan protocol, like any other flavor of Password-Authenticated Key Exchange (PAKE), is complex
and involves many cryptographic subtleties. However, at its core, it has an interaction that takes
place in the context of some existing relationship. Relying on a "pre-existing side channel" is not
a cheat or a cop-out, even though it felt like it at first. It's the core of this whole thing. How
does Alice know it's Bob? Because Alice and Bob had that interaction where Alice communicated the
invitation code to him, and Bob is able to prove that he's the one she had that interaction with.
The fact that this pre-existing channel exists at all is very significant; it only exists because
there is some kind of pre-existing relationship between Alice and Bob in the real world. So, that's
our answer: preexisting human interactions and relationships are what anchor identity.

**Q:** What anchors authority?

**A:** **The act of creation.**

Whether it's a company you founded, a project you started, or a document you created, the act of
creating something makes it yours and gives you authority over it. It doesn't automatically make you
a despot‚Äîit's up to you whether and how you want to delegate that authority‚Äîbut it gives you that
authority.

It only occurred to me as I was preparing this presentation that authority and authorship come from
the same root word. This is cool because it aligns with our conclusion: authority is rooted in the
act of authorship.

So, there are the answers to our big questions. I think they're good answers. This formulation feels
very satisfying and correct to me, and it puts us on very solid footing.

localfirst/auth is the implementation of these ideas in working code. There's a lot of interesting
stuff at the code level that I haven't had a chance to get into, but I'm happy to answer questions.
It's a work in progress, and I have many ideas about how to make it better, but it works today.
