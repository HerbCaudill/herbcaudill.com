---
title: Alice and Bob in wonderland
subtitle: Bootstrapping identity and authority in a world without servers

description: |
  In a client-server world, identity and authority are anchored in a server that logs people in and enforces permissions. When you take the server away, though, it might seem like there's 
  no solid foundation for authentication or authorization. Is there a principled way to establish trust in a distributed application?

date: '2024-05-28'
slug: local-first-auth
draft: false

caption: '"It would be so nice if something made sense for a change.‚Äù <i>‚Äî Lewis Carroll, Alice in Wonderland</i>'
tags: software
---

About four years ago, I first started thinking about authentication and authorization in a
local-first context. In was initially weird and confusing, like I'd stepped through the
looking-glass. I found myself wrestling with big philosophical questions like "where does authority
_ultimately_ come from?" and "what does it mean to _know_ someone?".

I'm going to walk you through my journey, from that initial disorientation to what I believe are
solid, principled approaches, in the course of developing the <a
href='https://github.com/local-first-web/auth'>@localfirst/auth</a> library.

### Why this is weird and confusing

It might not be obvious why this might be disorienting, so I'll explain.

<figure className='figure-b figure-2up'>

![]($$/with-server.png)

![]($$/without-server.png)

Without a server, it's not clear where authority or identity come from.

</figure>

Traditional authentication and authorization ultimately "root out" in a physical piece of hardware,
owned and controlled by a company that you've decided to trust. The hardware is a server that has
your username and password and rules about what you're allowed to do. It might be controlled by your
employer, or a SaaS provider, or a big tech company.

<figure className="figure-md">

![]($$/i-fart-in-your-general-direction-2.png)

The server is like a guard at the castle gates. If the server doesn't recognize you, it doesn't let
you in. If the server doesn't think you should be allowed to have something, it doesn't give it to
you.

</figure>

Of course, the whole point of local-first software is that we don't love that arrangement.

But when you take away that central server, you're losing the thing that all our notions of security
are anchored to.

If all you have is clients, who are peers ‚Äî which means they relate to each other as equals ‚Äî then
how do we know who is who? How do we know who to trust? What do permissions even mean ‚Äî who exactly
is "giving permission"?

<figure className="figure-xs">

![]($$/bootstrap-2.png)

"Bootstrapping" has become a word that we associate with something as easy and routine as turning
your computer on. But the whole point of bootstrapping as a metaphor is that _it's supposed to be
impossible_: You _can't_ lift yourself up by pulling on your bootstraps.

</figure>

It's like living in a monarchy and realizing that the king is just another person, and not someone
appointed by the gods. Just like countries making that transition from monarchy to democracy, we're
suddenly adrift, and have to come up with completely new arrangements to solve problems that were
already solved ‚Äî even if in a suboptimal way.

Without a server, it feels like we're having to pull ourselves up by our bootstraps on some
fundamental questions:

- **What anchors identity?** How do we authenticate with a peer device?
- **What anchors authority?** How do permissions work? Who has the authority to give anyone
  permission anyway?

### The road to localfirst/auth

In 2020, a couple of weeks into the pandemic, I started work on a library that became
localfirst/auth.

I had to learn about modern cryptography starting from zero.

I was immediately fascinated by how _empowering_ public-key cryptography is, in the sense that it
can put me on an equal footing with even very powerful adversaries.

<figure>

![]($$/hacker-meme.png)

The movies would lead you to believe that defeating encryption is something a dude in a hoodie can
do just by typing really hard.

</figure>

<aside>

<sup>\*</sup>As long as you didn't screw something up.

<sup>\*\*</sup>And as long as quantum computers haven't been invented yet.

</aside>

But in the real world strong cryptography can't be defeated.<sup>\*</sup> It just can't.<sup>\*\*</sup>

Here is legendary cryptologist and mathematician Daniel J. Bernstein writing [over a decade ago](https://eprint.iacr.org/2011/646.pdf):

> For most cryptographic operations, there exist widely accepted primitives that have been
> extensively studied, and breaking them is considered computationally infeasible on any existing
> computer cluster.

The point is you don't need a lot of money, or computing power, or specialized equipment. Strong
encryption doesn't cost any more than weak encryption. It doesn't cost any more to use a long
encryption key than a short one. It's just math. It's just code.

## With no servers, what anchors _identity_?

So anyway I'm sitting down to work on this, and the first thing that makes my head spin is, how do
you know you're talking to?

When we collaborate or communicate online using a traditional cloud-based platform, we can think of
the service provider as **vouching for us** ‚Äî introducing us to other people and confirming our
identity.

If I'm using Slack to talk to you, you know it's me because Slack says it's me, and you trust Slack.
And maybe Slack knows it's me because I logged in with Google: Google vouched for me, and Slack
trusts Google.

If we don't want to put our trust in a centralized third party, then who will vouch us?

In a system where everyone's a peer, then maybe peers could vouch for peers, in some kind of chain
of trust. But that chain has to be anchored somewhere: Maybe Charlie vouches for Bob to Alice, but
who vouches for Charlie?

### Managing public keys

Ignoring the infinite regress problem for the moment, it seems clear that the solution will be
something something public-key cryptography. But to do public-key cryptography, you need to know
people's public keys.

> "**Crypto is a tool for turning a whole swathe of problems into key management problems.** Key
> management problems are way harder than virtually all cryptographers think.‚Äù  
> ‚Äî _Dr. Lea Kissner_

Dr. Kissner was the head of information security at Twitter and I don't think they meant this
[tweet](https://twitter.com/LeaKissner/status/1198595109756887040) to be encouraging.

But I do find it encouraging. Even granting that key management is a hard problem, the idea that you
can collapse lots of different problems into this one problem is exciting, because you just have to
focus on solving that thing. If you can succeed at the key management thing ‚Äî it's is a big if ‚Äî but
if you can, then you can solve this "whole swathe of problems.‚Äù

So how do we learn people's public keys?

<figure className="figure-md">

![]($$/spain-cert.png)

Here in Spain, I can obtain a certificate from the treasury department to install in my browser,
which allows me to transparently authenticate to government websites and sign official documents
digitally.

</figure>

<figure className='figure-xs'>

![]($$/pgp-key.png)

This is what [my public PGP
key](https://keybase.io/hc3/pgp_keys.asc?fingerprint=33fe890a032e2915863b43f1cdd09cf0755686ec) looks
like.

</figure>

The most obvious solution is to have some trusted party keep a directory of people and their public
keys, and of course that‚Äôs totally a thing that exists.

The certificate authorities (CAs) that make secure https connections possible are an example. Some
big companies have their own certificate authorities to anchor their employees' digital identities.
And countries can do the same for residents.

### Bringing encryption to the nerd community

But we‚Äôre trying to do this without depending on centralized services.

If you want a decentralized solution, the alternative seems to be for people to actively share their
own keys directly with each other.

This was the approach taken by PGP (‚ÄúPretty Good Privacy‚Äù) in the 1990s.

PGP was the first encryption toolset intended for ordinary users. The idea was that people would put
their public keys on their websites and in their email signatures. Apparently there were key signing
parties where people exchanged and signed each other‚Äôs keys.

<figure className="figure-md">

![]($$/key-signing-party.png)

From the looks of it these parties were **_lit_**. <span className='text-lg'>ü•≥</span>

</figure>

In 2014, [Keybase](https://keybase.io/) had a better idea:
People can just post their public keys in machine-readable form on public sites where they have
accounts, like Twitter or GitHub. They called these "social proofs". Then anyone can look up a
person's public keys by username, and use them to verify their identity.

<figure className='figure-b figure-2up'>

![]($$/keybase-github.png)

![]($$/keybase-reddit.png)

I've used Keybase to "verify myself" by posting machine-readable statements on
[Twitter](https://twitter.com/herbcaudill/status/1252295765055156229),
[GitHub](https://gist.github.com/HerbCaudill/1a826885eacfebb60a6ff421d57a9e37), and
[Reddit](https://www.reddit.com/r/KeybaseProofs/comments/g4xt1n/my_keybase_proof_redditherbcaudill_keybasehc3/)

</figure>

### Bringing encryption to the masses

The first applications to truly bring end-to-end encryption to the masses were messaging apps. The
Signal protocol came out in 2013, and two years later WhatsApp brought it to their entire customer
base, and overnight about a billion people were using encrypted messaging. Since then WhatsApp's
user base grew to two billion and then to three billion, making it one of the most widely used
communication tools in all of human history.

This succeeded because they made encryption transparent to the user. The key insight is that a
public key will never be like an email or a telephone number. It's not a stable component of our
digital identity. Wrangling encryption keys is a job for computers, not for people. Devices should
just generate keys as needed and we should never see them or have to think about them. Private keys
should never leave the device, and public keys should be shared automatically with other devices.

<table>
  <thead>
    <tr>
      <th></th>
      <th><img src="$$/drake-no.jpg" alt="" /></th>
      <th><img src="$$/drake-yes.jpg" alt="" /></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td>
      <img src="$$/logo.pgp.png" className="size-[30px] md:size-[58px] inline" alt="PGP" />
      <img src="$$/logo.keybase.png"  className="size-[30px] md:size-[58px] inline"  alt="Keybase" />
      </td>
      <td>
      <img src="$$/logo.signal.png" className="size-[30px] md:size-[58px] inline" alt="Signal" />
      <img src="$$/logo.whatsapp.png"  className="size-[30px] md:size-[58px] inline"  alt="WhatsApp" />
      <img src="$$/logo.telegram.png" className="size-[30px] md:size-[58px] inline" alt="telegram" />
      </td>
    </tr>
    <tr>
      <td><strong>what</strong> is the scope of a key?</td>
      <td>one human identity</td>
      <td><b>one app on one device</b></td>
    </tr>
    <tr>
      <td><strong>who</strong> manages keys?</td>
      <td>humans</td>
      <td><b>computers</b></td>
    </tr>
    <tr>
      <td><strong>when</strong> do we see our keys?</td>
      <td>often</td>
      <td><b>never</b></td>
    </tr>
    <tr>
      <td><strong>how</strong> are keys shared?</td>
      <td>manually, human to human</td>
      <td><b>automatically, device to device</b></td>
    </tr>
  </tbody>
</table>

We're agreed, then, that device-to-device sharing of keys is better than key signing parties. But
Alice's device still needs to know that Bob's device is really Bob's device, and not Eve's device
pretending to be Bob's device.

### TOFU and other meat substitutes

<figure className='figure-xs'>

![]($$/tofu.png)

TOFU considered squishy. <i>Image: [Yoav Aziz](https://unsplash.com/@yoavaziz)</i>

</figure>

WhatsApp and Signal take an approach called "Trust On First Use", or TOFU. Here's how that works:

Here's the idea behind TOFU:

- When Alice invites Bob to communicate with her, she just **trusts** that the **first** person to
  show up saying they're Bob _is_, in fact, Bob.
- Bob and Alice exchange their public keys on that initial connection.
- From that point on, and on subsequent connections, they can use those keys to authenticate and
  encrypt messages to each other.

There's a little risk there, they're both taking a little leap of faith, but it's a one-time thing,
it's probably fine.

That seems reasonable. The problem, though, is that the "first use" bit is kind of misleading,
because **in practice TOFU doesn't happen just once**.

Remember, the keys we care about are device-level keys, not user-level keys. So what happens when
Bob gets a new phone, or Alice reinstalls the software on her laptop?

What happens is an "account reset", and at that point we're back to TOFU ‚Äî except that now, the
attack scenarios are a bit more plausible: an impostor might have engineered the reset, and it would
be more feasible to exploit it.

When a user has an account reset, the messaging apps suggest to everyone they communicate with that
they compare "security codes" or "safety numbers". Most users don't do this ‚Äî I never have, I can't
imagine that people less technical than me do this.

And anyway this is bad enough for a single pairwise connection; where this all really falls apart is
in a large group, where the number of pairwise connections scales exponentially with the size of the
group.

### PAKEs

<figure className='figure-xs '>

![]($$/pake-balanced-1.png)

With a balanced PAKE, both parties need to know the password.

</figure>

So when you want to connect with someone and don't know their public key, is there an alternative to
TOFU for securing that initial connection?

The most promising approach is to first share a single-use password out of band (in person, or via a
channel you already trust). There is whole a family of cryptographic protocols that support this, called
PAKEs (for ‚Äúpassword-authenticated key exchange‚Äù).

We're saying "password" but it's generally presented as an invitation code.

In the most common forms, both parties need to know the secret code; this is called a **balanced PAKE**.

The downside is that the inviter and invitee need to connect directly to validate the invitation.

<figure className='figure-xs '>

![]($$/pake-asymmetrical-2.png)

With an asymmetric PAKE, a third party can verify the password without knowing it.

</figure>

With an **asymmetric PAKE** (asymmetric because the verifier doesn't need to know the password) a third
party can validate an invitation code without knowing it in advance or asking for it.

### The Seitan token exchange

This brings us back to Keybase. In 2017 or so, they decided to try to monetize by building a
Slack-but-encrypted thing for enterprise customers. They quickly realized that even if the global
nerd population thought the idea of putting your public key on Twitter was really cool, Jim in
Accounts Payable is probably just not going to do that. Sorry, it's just not going to happen.

So they needed a way to bootstrap that initial key exchange, and they proposed something called a
[Seitan Token Exchange](https://keybase.io/docs/seitan) (presumably "seitan" because it's not as
soft as tofu).

This is the approach I stole for localfirst/auth. At the time I didn't know a PAKE from a hole in
the ground, but as it turns out this is essentially an asymmetric PAKE.

This is how it works:

<div className="lg:w-9/7">
  <div className="md:grid grid-flow-row grid-cols-2 [&_div]:pt-4 [&_div]:pr-4 [&_div]:pb-2 [&>div]:border-t">
  <div>
    <img src='$$/seitan-1.png'/>
    <div className='caption'>
      <b>1.</b> Alice creates an arbitrary password. This can be long or short ‚Äî it depends on the application's threat model. She derives a signature keypair from the password. 
    </div>
  </div>
  <div>
    <img src='$$/seitan-3.png'/>
    <div className='caption'>
      <b>2.</b> Alice invites Bob by giving him the password, and gives Charlie the public key of the signature keypair.
    </div>
    </div>
  <div>
    <img src='$$/seitan-5.png'/>
    <div className='caption'>
      <b>3.</b> Bob derives the same signature keypair from the password, and generates a proof by signing something with the private key.
    </div>
  </div>
  <div>
    <img src='$$/seitan-6.png'/>
    <div className='caption'>
      <b>4.</b> Bob sends Charlie the proof. 
    </div>
    </div>
  <div>
    <img src='$$/seitan-7.png'/>
    <div className='caption'>
      <b>5.</b> Charlie validates the proof with the public key Alice sent him. Charlie now knows that Bob is the person Alice invited. 
    </div>
  </div>
  <div>
    <img src='$$/seitan-8.png'/>
    <div className='caption'>
      <b>6.</b> Bob and Charlie can now exchange public keys, and Charlie can pass on Alice and Charlie's public keys to each other.
    </div>
  </div>
  </div>
</div>

### Identity is rooted in relationships

We've been talking about "identity"; but the beauty of this approach is that identity doesn't need
to mean "who you are in the world", in the sense of linking to your real name or email or whatever ‚Äî
it can just mean "who you are _to me_".

<figure className='figure-xs'>

![]($$/backchannel-screenshot.png)

Rather than linking identity to a name or an email address, we link it to a relationship.

</figure>

For example, in Ink & Switch's [Backchannel](https://www.inkandswitch.com/backchannel/) project one
of the motivating use cases was connecting an anonymous source to a journalist. With a system like
this the source doesn't have to have a name at all; the only thing that matters is that they're able
to interact once.

Trust and identity are ultimately rooted in real-world relationships and interactions between human
beings. I know you because we interact, whether that's face-to-face or online. **That's what it
means to "know" someone.** And we can use that interaction to bootstrap cryptographically secure
connections going forward. And if you have those secure connections with other people and I trust
you, I can benefit from your connections, and so on, forming a network of trust relationships.

That helps us clear up our thinking about identity:

**Q.** What anchors identity?

**A.** Real-world human **interactions** and **relationships**.

This feels correct to me: It's natural, human-scale, and rooted in social reality.

The server-centric model roots our identity in getting distant corporations to vouch for us.

- _Are you really Herb?_
- _Yes ‚Äî look, Google vouches for me._

With this model, instead can **we vouch for ourselves**:

- _Are you really Herb?_
- _Yes ‚Äî remember we talked earlier._

And we can **vouch for each other**:

- _I have a friend named Herb and this is how you'll know it's him._

## Without servers, what anchors _authority_?

<figure className="figure-xs">

![]($$/acl.png)

Is it possible to have a secure, distributed access control list?

</figure>

So now I have a way of knowing it's you. But how do I know if you're on my team? How do I know if I
should share this document with you, or if you should be able to edit it?

On a server this information is often recorded in some kind of **access control list** (ACL). So
maybe we need that, but distributed ‚Äî everybody needs a copy of the same list. How would that work?

My first thought was that we could just put this information in an Automerge document and replicate
it across everyone's devices that way. But we can't just let anyone edit this document at will. It
should be obvious if anyone changes the permissions, and we need to know _who_ changed the
permissions, and if they ‚Ä¶ had permission to do so? Do we need an ACL for the ACL?

Let's ignore that rabbit hole of infinite regress for the moment and focus on the mechanics. We need
a way of replicating a document that is:

‚úÖ **tamper-evident:** it shouldn't be possible for someone to surreptitiously modify the list

‚úÖ **eventually consistent**: everybody should have the same list

‚úÖ **authenticated**: we need to know who has written changes to the list

So let's look at some options for data structures.

### Hash chain

<aside>

A [**cryptographic hash**](https://en.wikipedia.org/wiki/Cryptographic_hash_function) is a unique, random-looking code generated from a message. It's like a
**fingerprint**: it's impossible (practically) for two messages to have the same hash. The slightest
change in the message gives a completely different hash.

</aside>

When we say "tamper-resistant" the first thing you might think of is a hash chain (or
**blockchain**), where each link contains a cryptographic hash of the previous link, so it's
impossible to modify one link or change the order without breaking the chain.

<figure>

![]($$/hash-chain.png)

<div>

hash chain

‚úÖ tamper-evident

</div>
</figure>

The problem is that this chain needs to be linear. Replicating it while ensuring consistency
requires enforcing a strict ordering; and cryptocurrency blockchains are famously ‚Ä¶ not optimized
for efficiency.

### Hash graph

<aside>

A [**CRDT**](https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type) (conflict-free replicated data type) is a combination of a data structure and algorithm
that allows multiple people to edit the same data concurrently, and then merge without conflicts.

</aside>

To accomplish this without burning enough fossil fuels to power multiple small countries, we could
use a **hash graph**. A hash graph is a hash chain plus branching. A CRDT like Automerge combines a
hash graph with automatic conflict resolution logic to support replication with eventual
consistency. Git works the same way but with manual conflict resolution.

<figure>

![]($$/hash-graph.png)

<div>

hash graph

‚úÖ tamper-evident  
‚úÖ eventually consistent

</div>

</figure>

So far so good. But we still need a way of verifying who made which changes to our distributed
access control list.

### Signature graph

A **signature graph** is a hash graph where the individual operations are signed by the author. This
gives us all three things.

<figure>

![]($$/signature-graph.png)

<div>

signature graph

‚úÖ tamper-evident  
‚úÖ eventually consistent  
‚úÖ authenticated

</div>

</figure>

If you look at the work of anyone who's trying to tackle this problem, you're going to see some kind
of signature graph: [Matrix](file:///Users/herbcaudill/Downloads/2011.06488.pdf),
[HALO](https://docs.dxos.org/guide/halo/), [UCANs](https://github.com/ucan-wg/spec), etc. It's a
case of convergent evolution ‚Äî we've all more or less independently landed on this data structure.

### A group membership CRDT

The way this works, concretely, is that there's a series of operations on the group:

- The first link, the **root** of the chain, marks the creation of the group and by definition adds
  the founder to the group as an admin. It also includes the founder's **public keys**.

- Each subsequent link represents an administrative **action** such as inviting a member, removing a
  member, promoting a member to admin (or another role), or demoting a member.

- Each link contains a **cryptographic hash** of the preceding link, so the order of the links
  cannot be altered.

- Each link contains a **digital signature** of its content by the member making the change, so that
  its authenticity can be independently verified, and so that the link body cannot be tampered with.

<aside>

This is not democratic, but that's OK because the only thing at stake here is the ability for
members to communicate with each other. If Dwight is the only admin and he is being a despot,
everyone else can just start a new group without him, and then decline to communicate with him. This
is analogous to how the **right to fork** keeps open source maintainers from wielding power
tyrannically.

</aside>

When Alice creates a group, she is the group's only member and the group's only admin. Suppose she
adds Bob, Charlie, and Dwight. Then:

> - üë©üèæ Alice promotes üë®üèª‚Äçü¶≤ Bob to admin
> - üë®üèª‚Äçü¶≤ Bob promotes üë≥üèΩ‚Äç‚ôÇÔ∏è Charlie to admin
> - üë©üèæ Alice removes üë®üèª‚Äçü¶≤ Bob
> - üë≥üèΩ‚Äç‚ôÇÔ∏è Charlie removes üë¥üèº Dwight

When Charlie removes Dwight, how do I know that's a legitimate change? Well, if I look back through
the history of changes, I can see that:

> - üë≥üèΩ‚Äç‚ôÇÔ∏è Charlie was an admin at the time he removed üë¥üèº Dwight
> - üë≥üèΩ‚Äç‚ôÇÔ∏è Charlie was promoted to admin by üë®üèª‚Äçü¶≤ Bob
> - üë®üèª‚Äçü¶≤ Bob was an admin at the time he promoted üë≥üèΩ‚Äç‚ôÇÔ∏è Charlie
> - üë®üèª‚Äçü¶≤ Bob was promoted by üë©üèæ Alice
> - üë©üèæ Alice was an admin at the time she promoted üë®üèª‚Äçü¶≤ Bob
> - üë©üèæ Alice's original admin rights come from having created the group

In this way we can conclude that Charlie's admin rights are legitimate because they can ultimately
be traced back to Alice.

Note that even though Bob was ultimately removed from the group, he was a member with admin rights
when he promoted Charlie. His promotion of Charlie remains valid from that point forward, unless and
until another admin removes or demotes Charlie.

This works the same way no matter how long ago the group was created, no matter how much turnover
there is, and whether or not Alice is even a member any more.

### Detecting and resolving conflicts

To be replicable, this data structure needs to be a CRDT. However, you can't model group permissions
using a JSON CRDT like Automerge. I'll explain why.

Here we have two concurrent actions, but there's no conflict, and we can resolve this by picking one
or the other in an arbitrary but deterministic order. So far, nothing Automerge couldn't handle.

What if someone takes actions while concurrently being removed? What happens if Bob adds Charlie to
the group and concurrently, Alice removes Bob from the group? Now we have a **conflict**. Is Charlie
in the group or not? It's important to resolve this correctly, or else Bob could circumvent his
removal by writing a concurrent operation adding proxy-Bob to the group.

A: Removals always take precedence. We resolve that conflict by **prioritizing removals**. A generic
CRDT like Automerge won't be able to resolve this conflict in a principled way; it won't even see it
as a conflict. So, we have to build a custom CRDT engine.

### Mutual removals

What if two admins remove each other concurrently? (Or more generally, what if there's a cycle of
concurrent removals?)

As a scenario involving two legitimate members of the group, this is far-fetched and unlikely to
happen. A more realistic and worrying scenario might be, for example, a compromised and revoked
device trying to undo its revocation.

- **Option 1: Remove Both** The logical conclusion of "removals take precedence" is to remove both.
  However, this seems unlikely to be the correct way of resolving the issue. It leaves Charlie
  orphaned in a group without admins and creates an opening for a denial-of-service attack, where a
  rogue device blows up the group rather than allowing itself to be removed.

- **Option 2: Fork the Group** Another approach is to "fork the world" into two parallel versions of
  the same group: one where Alice stays and one where Bob stays. Then each member decides which
  world they want to live in. This reflects the reality of a decentralized system. I call this the
  Papal Schism solution, in honor of the time when there were two popes and all of Catholic
  Christendom had to decide which one to follow.

- **Option 3: Keep the Senior Member** The solution I settled on is to let seniority be a proxy for
  who is more likely to be in the right. In this case, Alice has been in the group longer than Bob,
  so she stays.

### Authority is rooted in authorship

The key insight for me was that the root node of the group's signature graph gives you an anchor for
authority. If I create a group, by definition I get to decide who's in it. At the moment of
creation, I am the absolute dictator of a group with no other members. I decide who to add to the
group and whether I want to delegate my authority to other members. I can make everyone else an
admin, or even delegate the right to remove me from the group. Even once I'm gone, the authority
behind any action‚Äîany addition or removal of members, any further delegation of authority‚Äîcan always
be traced back to the authority inherent in my act of creation.

## Some conclusions

We started with two big questions about how we find our footings in a local-first world.

**Q:** What anchors identity?

**A:** **Preexisting human relationships and interactions.**

The Seitan protocol, like any other flavor of Password-Authenticated Key Exchange (PAKE), is complex
and involves many cryptographic subtleties. However, at its core, it has an interaction that takes
place in the context of some existing relationship. Relying on a "pre-existing side channel" is not
a cheat or a cop-out, even though it felt like it at first. It's the core of this whole thing. How
does Alice know it's Bob? Because Alice and Bob had that interaction where Alice communicated the
invitation code to him, and Bob is able to prove that he's the one she had that interaction with.
The fact that this pre-existing channel exists at all is very significant; it only exists because
there is some kind of pre-existing relationship between Alice and Bob in the real world. So, that's
our answer: preexisting human interactions and relationships are what anchor identity.

**Q:** What anchors authority?

**A:** **The act of creation.**

Whether it's a company you founded, a project you started, or a document you created, the act of
creating something makes it yours and gives you authority over it. It doesn't automatically make you
a despot‚Äîit's up to you whether and how you want to delegate that authority‚Äîbut it gives you that
authority.

It only occurred to me as I was preparing this presentation that authority and authorship come from
the same root word. This is cool because it aligns with our conclusion: authority is rooted in the
act of authorship.

So, there are the answers to our big questions. I think they're good answers. This formulation feels
very satisfying and correct to me, and it puts us on very solid footing.

### localfirst/auth

localfirst/auth is the implementation of these ideas in working code. It's a work in progress, and I
have many ideas about how to make it better, but it works today. If you take it out for a spin ‚Äî or
if you have questions about how it works ‚Äî please get in touch with me via one of the pre-existing
trusted side channels listed below

This project‚Äôs shape emerged from a series of conversations early on with Peter Van Hardenberg of Ink & Switch. Peter drilled into my head the idea that device keys should be generated locally and never leave the device, and pointed me towards Keybase‚Äôs signature chains. The framing of permission vs. attention is his as well.

As the above makes clear, Martin Kleppmann has been very generous with his time and expertise, and has gotten me unstuck more than once. Martin is the creator of Automerge and co-author with Peter of Ink & Switch‚Äôs local-first manifesto. In my experience, 100% of the time he has a PDF up his sleeve that solves your exact problem.
