---
title: Cryptography 101
subtitle: Everything you need to know about digital encryption and signatures but were embarrassed to ask.

description: |
  Cryptography is a fundamental piece of the digital infrastructure we all rely on, and yet most of
  us are pretty fuzzy on how it actually works. I've written this for programmers — as well as
  curious civilians — who would like a clearer idea of what the pieces are and how they fit together.

draft: true

date: '2021-03-23'
tags: software

caption: |
  In this 1804 letter to James Monroe, James Madison encrypted the sensitive parts using the
  <a href="http://cryptiana.web.fc2.com/code/state.htm#monroe2">Monroe Cipher</a> — one of many
  secret codes in use at that time that worked by assigning numbers to words and syllables.  
  <i>Image: Public domain, <a href="https://www.loc.gov/resource/mjm.08_0143_0147/?sp=4">Library of Congress</a></i>
---

Modern digital cryptography can be intimidating, even for seasoned programmers and other smart
people. When I first started work on
[@localfirst/auth](/words/20210228-establishing-trust-in-a-world-without-servers), I felt so
self-conscious about my own ignorance of some really basic stuff that I hesitated to ask my peers
for pointers.

And there was a gap in the educational materials available online between hand-wavy things that only
explained by way of analogy, and in-the-weeds things that only explained by way of inscrutable
mathematical proofs. I wanted to have a clear grasp of the math at work, without needing to get a Ph.D. first.

The good news is that I've found that that _is_ possible: The basic concepts underlying cryptography are
actually well within reach using nothing but high-school math.

The purpose of this article is to explain cryptography while still respecting your intelligence. I'll
focus on these five operations:

1. [Symmetric encryption](#-symmetric-encryption)
2. [Random number generation](#-random-number-generation)
3. [Hashes](#-hashes)
4. [Signatures](#-signatures)
5. [Asymmetric encryption](#-asymmetric-encryption)

But first, a quick reminder about the nature of digital data.

## Prologue: Numbers all the way down

<figure class='figure-xs'>

![]($$/ascii.png)

The [ASCII](https://en.wikipedia.org/wiki/ASCII) standard defined numerical equivalents for 95
printable characters: upper-case **A** is 65, lower-case **z** is 122. The
[Unicode](https://en.wikipedia.org/wiki/Unicode) standard has expanded on that to encode 143,859
characters in 154 scripts, from Cyrillic to Hiragana to Emoji.

</figure>

The first intuition required to understand digital cryptography is that **everything is
numbers**. That's what "digital" means. Whether it's an instant message or a scan of your bank
statement, it's a series of numbers.

This may or may not be obvious to you, but what it means is that we can think of all of the
operations listed above as functions that take a number and return a different number.

In this article I'll focus on messages consisting of **text**, like `The eagle lands at midnight`.
Over time, we've come up with lots of different ways to express letters and characters as numbers.
The only encodings that matter for our purposes is Unicode (which is a superset of ASCII).

In both ASCII and Unicode, the message `The eagle lands at midnight` is encoded as follows:

```txt
T  h   e      e   a  g   l   e      l   a  n   d   s      a  t      m   i   d   n   i   g   h   t
84 104 101 32 101 97 103 108 101 32 108 97 110 100 115 32 97 116 32 109 105 100 110 105 103 104 116
```

<div class='exercises'>

### See for yourself

1. Write a function that takes an ASCII string and encodes it as an array of bytes.
1. Write a function that takes an array of bytes and decodes it back into a string.
1. Use the [utf8.js](https://github.com/mathiasbynens/utf8.js) package to encode Unicode strings
   into an array of bytes.

</div>

## <span></span> Symmetric encryption

<aside>

In **asymmetric** encryption, also known as **public-key** encryption, the sender
and receiver have different keys. We'll look at that later.

</aside>

**Symmetric** (secret-key) encryption is one way of encoding information so that no one can decode
it without a secret key. It's called "symmetric" because both the sender and the receiver have the
same secret key.

Suppose Alice wants to send our message, `The eagle lands at midnight`, to Bob. Both she and Bob
know the secret passphrase `Horse Battery Correct Staple`.

Alice converts the message to binary. `84` in binary is `01010100`, `104` is `01101000`, and so on.

```txt
T        h        e        space    e        a        ...
84       104      101      32       101      97
01010100 01101000 01100101 00100000 01100101 01100001
```

She also converts the passphrase to binary.

```txt
H        o        r        s        e        space    ...
72       111      114      115      101      32
01001000 01101111 01110010 01110011 01100101 00100000
```

<aside>

XOR (also notated ⊕) is an operation on two binary digits that returns **1** if the two digits are
**different**, and **0** if they are the **same**:

0 ⊕ 0 = 0  
0 ⊕ 1 = 1  
1 ⊕ 0 = 1  
1 ⊕ 1 = 0

</aside>

To encrypt the message using the passphrase, she takes each bit of the message and the corresponding
bit of the passphrase, and performs an `XOR` operation to come up with a new binary number:

```txt
    01010100 01101000 01100101 00100000 01100101 01100001 ... (message)
XOR 01001000 01101111 01110010 01110011 01100101 00100000 ... (passphrase)
---------------------------------------------------------
    00011100 00000111 00010111 01010011 00000000 01000001 ... (cipher)
```

```txt
    The eagle lands at midnight   (message)
XOR Horse Battery Correct Staple  (passphrase)
--------------------------------

    546865206561676C65206C616E6473206174206D69646E6967687400
XOR 486F727365204261747465727920436F727265637420537461706C65
-------------------------------------------------------------
    1C0717530041250D115409131744304F1306450E1D443D1D06181865
```

We call the result of this operation a **cipher**: It's the

She gets the following **cipher**, which she can send to Bob:

```txt
00011100 00000111 00010111 01010011 00000000 01000001 ...
```

The `XOR` operation has the useful property that you can run it "backwards" to retrieve one of the
original inputs: if `A ⊕ B = C`, then `C ⊕ B = A`. So when Bob receives the cipher, he can `XOR` it
with the passphrase to recover the original message:

```txt
    00011100 00000111 00010111 01010011 00000000 01000001 ... (cipher)
XOR 01001000 01101111 01110010 01110011 01100101 00100000 ... (passphrase)
---------------------------------------------------------
    01010100 01101000 01100101 00100000 01100101 01100001 ... (message)
```

If the key is as long or longer than the message and you never re-use it, it's equivalent to a spy's
**one-time pad**, which is the gold standard for encryption: It offers **perfect secrecy** because
it is mathematically impossible to crack.

What happens if the message is longer than the key, though?

We _could_ repeat the key as many times as necessary to have a mask that's as long as the text to be
encrypted. Suppose the key is `passw0rd`:

```txt
    The eagle lands at midnight
XOR passw0rdpassw0rdpassw0rdpas
```

This would work, but it would not be very secure. To show why, let's take it to an extreme: Suppose
our key is just the letter **X** (`01011000` in binary).

```txt
    The eagle lands at midnight
XOR XXXXXXXXXXXXXXXXXXXXXXXXXXX
```

```txt
    01010100 01101000 01100101 00100000 01100101 01100001 ... (message)
XOR 01011000 01011000 01011000 01011000 01011000 01011000 ... (repeated key)
    ------------------------------------------------------------
    00001100 00110000 00111101 01111000 00111101 00111001 ... (cipher)
```

If you've ever solved a "cryptogram" in a newspaper or a puzzle book, you might see the problem with
this approach. A cryptogram is an example of a **substitution cipher**: each letter in the alphabet
is substituted with another. For example, this cipher substitutes **A** for **E**, **Q** for **T**,
and so on:

```txt
THE EAGLE LANDS AT MIDNIGHT
QDA AZCIA IZKRP ZQ JFRKFCDQ
```

Substitution ciphers can be solved so easily that they put them in the newspaper next to crossword
puzzles, so that people can work them out with pencil and paper for fun.

<figure class='figure-md' >

![]($$/cryptogram.jpg)

If your grandpa can crack it over coffee, it's probably not secure.

</figure>

<figure class='figure-xs'>

![]($$/distribution.png)

In English, **E** is the most common letter, followed by **T**, then **A**, **I**, **N**, **O**, and **S**.
_Source: [Practical Cryptography](http://practicalcryptography.com/ciphers/caesar-cipher/)_

</figure>

How? For one thing, you can use statistics about letter frequency to your advantage: A letter that
appears 12% of the time is likely to be `E`, and so on. The longer the message is (or the more
messages you have to work with) the bigger our statistical sample and the more helpful this
technique is.

Our example of XOR encryption with a repeated single-letter key is just a substitution cipher: Every
**T** (`01010100`) is replaced with `00001100`; every **E** (`01100101`) is replaced with
`00111101`; and so on.

With a longer repeated key like `passw0rd` this wouldn't be quite as easy, but given a long-enough
message, it's still possible. The same logic applies to re-using the same key for multiple messages:
The more examples you have of messages encrypted using the same key, the better your chances of
cracking the code.

How can we securely encrypt a message using a key that's shorter than the message?

In order for our symmetric encryption algorithm to be secure, what we need is a way to "stretch" our
key to the size of the message, **without** repeating it. We'll look at a way to do that, but first
we need to talk about random and pseudo-random numbers.

<div class='exercises'>

### See for yourself

<aside>

A **keyed Caesar cipher** is a substitution cipher that is created using a keyword. Suppose the keyword
is `HIERONYMUS`, then the cipher is as follows:

```txt
ABCDEFGHIJKLMNOPQRSTUVWXYZ
HIERONYMUSABCDFGJKLPQTVWXZ
```

(Note that the keyword must not have any repeated letters.)

In this example, `THE EAGLE LANDS AT MIDNIGHT` becomes `VAM MRSFM FRJYT RV GBYJBSAV`.

</aside>

1. Write a `makeCryptogram` function that takes a message and a keyword, and uses a [keyed Caesar
   cipher](TODO) to create a cryptogram.

2. Write an `encrypt` function that takes a message and a key, and using the `XOR` approach described
   above, returns the encrypted message as an array of bytes.

3. Write a `decrypt` function that takes a cipher (generated by the `encrypt` function) and a key,
   and returns the original message.

4. **Nerds only** 🤓  
   Write a `solveCryptogram` function that uses the approach described in [this
   article](https://www.ics.uci.edu/~welling/teaching/271fall09/Cryptopaper-hart.pdf) to solve any
   cryptogram.

</div>

## <span></span> Random number generation

A source of **unpredictability** is a fundamental requirement for any form of information security. If
you can make educated guesses about the next key that a system will generate, then the system's
secrets are no longer secret.

**People** can be a source of randomness. In the examples above, we have Alice and Bob using a secret
passphrase --- `Horse Battery Correct Staple` --- to encrypt and decrypt. That might seem totally
random to you --- unless you've seen this XKCD cartoon.

<figure class='figure-md'>

![Password Strength](https://imgs.xkcd.com/comics/password_strength.png)

Since this passphrase appeared in this cartoon, it's no longer a good choice --- but that hasn't
stopped people from using it!

</figure>

Using people to generate randomness doesn't work very well. For example, the passwords we humans
come up with are often not as random as we think they are. This is partly because we shrink the
total possibility space in various ways that make our passwords easier to remember; thus `passw0rd`
and `abc123`.

<figure class='figure-xs'>

![](https://miro.medium.com/max/640/1*pMNDxIQh72rFs7lsW6Ww0w.png)

TODO caption [credit](https://medium.com/@markshovman/human-generated-randomness-ac0e3d2f394f)

</figure>

But even if you take memorability out of the picture --- say, by asking someone to
type a series of random numbers --- the results are more predictable than we might think.

At any rate, encryption keys are typically not generated by us humans, but by our devices --- our
laptops, our servers, our smartphones. So how well do computers do at generating randomness?

This is a harder problem than it seems. You wouldn't think that unpredictability would be in short
supply. Unpredictability is maybe the most salient feature of physical reality.

> "It is difficult to make predictions, especially about the future." <i>--- (probably not) Yogi Berra</i>

In the natural world, entropy is the rule, not the exception. Any victories that we achieve against
it are fleeting in the inexorable march towards the heat death of the universe.

That's why we invented computers; they're a weapon for humanity in this battle against chaos.
They're state machines. Their whole point is to be orderly and predictable. Same input, same output,
every single time.

But what that means is that computers can't really **do** unpredictability. That's the bad news. The
good news is that we are surrounded by entropy, and the trick is to bring that outside randomness
into the computer.

<figure>

![Cloudflare's wall of lava lamps](https://blog.cloudflare.com/content/images/2017/11/lava-lamps.jpg)

As a source of entropy, Cloudflare's wall of lava lamps is mostly for show. But it does illustrate
the idea that true randomness has to come from the physical world into the computer.

</figure>

The internet company Cloudflare famously has a wall of lava lamps in their San Francisco lobby. The
movement of the blobs of wax in the hot oil in a lava lamp is known to be chaotic. A video feed from
a camera monitoring the lava lamps --- plus an additional bit of randomness from the movement of
people in the lobby --- populates an "entropy pool" from which random numbers can be drawn. And it
[doesn't stop there](https://www.cloudflare.com/learning/ssl/lava-lamp-encryption/):

> "The other two main Cloudflare offices are in London and Singapore, and each office has its own
> method for generating random data from real-world inputs. London takes photos of a double-pendulum
> system mounted in the office (a pendulum connected to a pendulum, the movements of which are
> mathematically unpredictable). The Singapore office measures the radioactive decay of a pellet of
> uranium."

The lava lamps and the uranium pellet are more nerdy PR stunts than anything. Any modern device has
several sources of randomness:

- Actual physical sensors like accelerometers and CPU temperature monitors
- Minute variations in input from the user, such as mouse movements and the millisecond-level timing
  of keystrokes
- Details of system's overall state, such as hard drive utilization, IDs of running processes, the
  system clock, or CPU counters

All of these can be combined to create something that's unpredictable enough that we don't need to
keep our webcams pointed at a lava lamp. Modern devices use techniques like these to provide
programmers with truly random numbers.

<div class='exercises'>

### See for yourself

1. Use `window.crypto.getRandomValues` (in the browser) or `crypto.randomBytes` (in NodeJS) to
   generate an array of 32 random bytes.

</div>

## <span></span> Pseudo-random number generators

<figure class='figure-xs'>

![JohnvonNeumann-LosAlamos.gif](https://upload.wikimedia.org/wikipedia/commons/5/5e/JohnvonNeumann-LosAlamos.gif)

"Anyone who considers arithmetical methods of producing random digits is, of course, in a state of
sin.” <i>--- John von Neumann</i>

</figure>

Pseudo-random number generators (PRNGs) are used to generate a series of random-looking numbers.
They are typically initialized with a numeric **seed**, which is generated by a genuinely entropic
process; and their results are **deterministic** --- if you use the same seed, you'll always get the
same sequence of numbers.

What we mean, exactly, when we say "random-looking" is the subject of many a doctoral thesis; but at
minimum this is what we want from a PRNG:

- Different seeds should generate different sequences.
- Any given sequence should be statistically indistinguishable from "truly random" numbers.

Some PRNGs are pure functions that take a number and return a new number. These PRNGs generate a
deterministic sequence by using each result as the seed for the next calculation; so if you know
_X_<sub>_n_</sub> you can always calculate _X_<sub>_n+1_</sub>.

The sequence that you can generate this way isn't infinitely long: at some point, you're bound to
get the original seed back as a result, and then you'll start to repeat the whole sequence.

<aside>

The Mersenne Twister, a widely-used PRNG invented in 1997, has a period of 2<sup>19937</sup> − 1.
In decimal, that's a 6000-digit number. (By way of comparison, the number of atoms in the universe is an
80-digit number.)

</aside>

The length of the sequence that you get before you start repeating yourself is called the PRNG's
**period**. The longer the period, the more useful the PRNG.

### PRNGs vs CSPRNGs

PRNGs that seed themselves with each previous result are perfectly fine for things like simulations
and videogames. But if any value generated by a PRNG can be used to predict all future values, then
you can't use it to generate secrets.

A **cryptographically secure PRNG** (CSPRNG) maintains a hidden internal state, so that you can't
use any values it generates to predict any other values it will generate in the future, or any
values it generated previously. (Or, of course, the value that was originally used as a seed.)

### Sometimes pseudo-random is what you want

Cryptographically secure or not, I always kind of figured that pseudo-random number generators were,
as the name suggests, just a poor substitute for a source of real random numbers.

It is true that you always need _some_ source of "truly" random numbers, if only for your
initial seed. And we often use PRNGs when there's not enough real entropy to go around. The
system-level sources of entropy change too slowly to be a computer's sole source of random numbers,
so they're typically not used directly; instead they're used to seed PRNGs.

But PRNGs themselves are powerful and essential tools. There are many situations where we need
strings of numbers that are **arbitrary but predictable**. Both types of "randomness" are used
extensively in modern cryptography --- the kind that can be predicted from a seed, and the kind that
can't be predicted at all --- and in many cases a deterministic but "random-looking" sequence is
what you want.

### Stream ciphers: Pseudo-randomness to the rescue

Case in point: the symmetric encryption problem that we left unsolved earlier.

> How can we securely encrypt a message using a key that's shorter than the message?

The answer is that we can use a PRNG to turn our key into a stream of numbers long enough to match
the message's length. (The PRNG's period has to be longer than the message we're encrypting!) Then,
we can `XOR` that stream and the message to produce an encrypted message. So instead of repeating
the key over and over...

```txt
    The eagle lands at midnight
XOR passw0rdpassw0rdpassw0rdpas
```

... we use the key to generate a long stream of randomness:

```txt
PRNG(passw0rd) = g77yL4zBl33d713fm8zOxO1mrrLigBmoLPbF...
```

We can then use that stream instead of the secret key itself to encrypt the message:

```txt
    The eagle lands at midnight
XOR g77yL4zBl33d713fm8zOxO1mrrLigBmoLPbF...
```

Anyone who has the secret key can generate the same random stream, and in turn use that to decrypt
the message.

<div class='exercises'>

### See for yourself

Before the Mersenne Twister was invented, the [linear congruential
generator](https://en.wikipedia.org/wiki/Linear_congruential_generator) (LCG) was a widely-used type of
PRNG. LCGs have the form

_X_<sub>_n_+1</sub> = (_aX_<sub>_n_</sub> + _c_) % _m_

(% is the modulo operator.)

1. Make a linear congruential PRNG using _a_=33, _c_=11, and _m_=100:

   _X_<sub>_n_+1</sub> = (33 _X_<sub>_n_</sub> + 11) % 100

   What is the period of this generator?

2. Repeat this exercise with _a_=8121, _c_=28411, and _m_=134456:

   _X_<sub>_n_+1</sub> = (8121 _X_<sub>_n_</sub> + 28411) % 134456

   What is the period of this generator?

3. Use the PRNG from the previous exercise to create symmetric `encrypt` and `decrypt` functions.

4. **Nerds only** 🤓  
   Based on the algorithm described in its Wikipedia article, implement one of the following PRNGs:

   - [Mersenne twister (MT19937)](https://en.wikipedia.org/wiki/Mersenne_Twister#)
   - [XorShift128+](https://en.wikipedia.org/wiki/Xorshift)

</div>

## <span></span> Hashes

A **hash function** scrambles a message in such a way that although you always get the same output,
you can't recover the original message from that output.

In mathematical terms, it's a function _h_(_a_) = _x_ that takes a number and returns a number. For
any _a_ you'll always get the same result _x_. And even if you know _x_ **and** you know how it was
calculated, it's infeasible to back out what _a_ was without just trying every possible value of
_a_.

Conceptually, there's a lot of overlap between hashing functions and PRNGs:

- They're both **deterministic**.
- They're both **one-way functions**.
- They both generate **random-looking** output (statistically indistinguishable
  from random noise).

The main difference is that while a PRNG are intended to go on and on, a hash is designed to be
short and sweet. Whether the input is a single digit or a huge document, the output has a fixed
length. For example, the MD5 algorithm always generates a 16-byte result, whereas the SHA-512
algorithm always generates a 64-byte result.

```txt
MD5('passw0rd') = bed128365216c019988915ed3add75fb
SHA512('passw0rd') = e0469addd8d57a3623494096dabc19bebca1a038c9da696940b3f853d106a6ecfa5bd60ce8e72884efa3bd92b930da178fd616f40facad654212d7c2f8817dd4
```

A good hashing algorithm has a couple more desirable features:

- Its output **varies chaotically**, so that the hashes of similar inputs are wildly different. This
  is referred to as the **avalanche effect**, which in turn is an example of the **butterfly
  effect**: The slightest change in the input --- even changing one character in a 1000-page
  document --- results in a completely different hash.
- Given one input, you can't calculate a **collision** --- a different input that results in the
  same hash --- without resorting to brute force.

> An optional digression into information theory:  
> **How can a function be both deterministic and irreversible?**
>
> At first blush, it might be hard to imagine how a function can be both one-way and deterministic:
> If you take a number and then use mathematical calculations to come up with a new number, how can
> you not just reverse those steps to back out what the original number was?
>
> The answer is that some mathematical operations "lose" information. In the case of the toy PRNG
> formulas used in the exercises above, like _X_<sub>_n_+1</sub> = (33 _X_<sub>_n_</sub> + 11) %
> 100, the information loss happens in the **modulo** operation.
>
> Suppose I tell you that some number, modulo 100, is 42. What can you say about that number? Only
> that (in decimal) it ends in 42. There's an infinite number of possibilities: 42, 142, 77777742,
> 424242, 38243978342, 1000000042, and so on.
>
> You could also simply truncate the number or discard selected digits. However it's done, every
> hashing algorithm has some step --- often repeated in a cycle --- that systematically throws away
> some information to prevent us from reconstructing the input.
>
> The inevitable implication is that for any given hash, there are many possible inputs. (Think
> about it: Messages have no size limit, so there are infinite possible messages. But hashes have a
> fixed size, so there are finite hashes available. If every message has a hash, then at least some
> hashes must be shared by an infinite number of messages.)
>
> But that's OK, because infinity is a big place. A well-designed hash function can still ensure
> that it's computationally infeasible to engineer a hash collision, and that accidental collisions
> don't happen in practice.

Some uses of hashes include:

- Systems with password-based logins use hashes to **avoid storing your password**, so that an
  attacker who steals their database doesn't get everyone's passwords for free. Rather than save
  your password itself, they calculate a hash of it and store that instead. When you log in, they
  hash your input and compare that to the stored hash.

- **Zero-knowledge proof**: More generally, hashes make it possible to verify that someone knows a
  secret without divulging the secret itself. Suppose I want you to be able to confirm independently
  that you got the right answer to a math problem. Instead of giving you the answer itself, I can
  give you the _hash_ of the answer. If you calculate the same hash, you got the right answer.

- **Fingerprinting data**: A large document can be identified uniquely using a compact hash. This
  can be used for error correction or to prevent tampering. As we'll see next, this usage of hashes
  is fundamental to how digital signatures work.

- **Stretching a short string**: As we saw with string ciphers, it can be useful to take a short
  secret and turn it into a long secret, without using repetition or other patterns that leave
  statistical traces.

<div class='exercises'>

### See for yourself

1. Implement dbj2 TODO

what else?

</div>

## <span></span> Asymmetric (public-key) encryption

Symmetric encryption, if done right, provides secrecy that is practically impossible to crack.

The problem with symmetric encryption is that we both need to know the secret key. So you and I
could meet in person, say, and agree on a key. But what if that key is compromised? (I told you not
to put it on a yellow sticky note on your monitor!) Do we then have to meet in person again? Or what
if meeting in person never was an option? I could try and get it to you through some other channel,
but then how do we secure _that_ channel? We're back where we started.

And if you have _N_ individuals that need to communicate with each other, what do you do? Now you
have _N!_ problems.

The solution to this problem is a surprisingly recent development: In 1976, two mathematicians at
Stanford University --- Whitfield Diffie and Martin Hellman --- came up with a way for Alice to send
Bob a secret message _even if the two had never communicated before_.

> If this sounds ridiculous, it should. It sounds impossible. If you were to survey the world's
> cryptographers in 1975, they would have told you it was impossible.  
> <i>--- Bruce Schneier, [Secrets and Lies](https://www.amazon.com/Secrets-Lies-Digital-Security-Networked/dp/1119092434)</i>

The math behind asymmetric encryption relies on **trapdoor functions** --- another category of
one-way functions. In this case, these are calculations that are easy to do but _very hard_ to
reverse.

Public-key encryption is based on the fact that it's easy to multiply two big prime numbers
together, but vastly harder to figure out what the two numbers were. So much harder that it's
impossible as a practical matter, if the numbers are big enough.

Suppose I choose two prime numbers at random --- say `907` and `113`. I multiply them together and
get `102491`. Now I give you that product and ask you to tell me what two prime numbers I
multiplied together. How would you do it?

- Perhaps you start by seeing if it's divisible by 2: nope!
- Then by 3: nope!
- Then by 4 ... but 4 isn't prime, so I can skip it.
- By 5: nope!
- And so on through the prime numbers: 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61,
  67, 71, 73, 79, 83, 89, 97, 101, 103, 107 ...
- By 109: nope!
- By 113: yes!!

Now you just divide 102491 by 113 to get 907 and you're done.

"Very hard, my ass!" you might be saying now. OK, then --- let's take it up a notch. Now I choose
two larger numbers: `31060011417247013446386700292411` and `15828351641710476406499702166851`. I can
still use a computer to multiply those two numbers together in a millisecond, to get
`491628782707727906284029372629196460298670083807451692011067761`. I could even do it by hand if I
had enough time and motivation.

But if I give you that result, the brute-force method you just used would require testing something
like 10^32 possibilities. If you could test _one billion_ candidates a second, it would take 10^23
seconds --- about **100,000 times the lifetime of the universe**. And you can't do much better than
brute force.

### How it works

In asymmetric encryption, everyone has a **keypair** with two parts: a **public key**, which you can
think of as the product of the two primes; and a **private key** (or secret key), which you can
think of as the prime factors themselves. Using the first example above, your private key might be
`907:113` and your public key `102491`.

Your public key, you can broadcast to the whole world: You could put it on the front page of your
website, or in the footer of every email you send. Your private key is never shared with anyone.

When Alice wants to send Bob a message, she encrypts it using Bob's public key. When Bob receives
the message, he can decrypt it using his private key.

TK Let's do an example using small numbers, to make the arithmetic easier to follow.

### Asymmetric encryption in practice: How a secure web connection works

When you visit a website using the `https` protocol (rather than `http`), you establish an encrypted
connection with the server. That encrypted connection is _made possible_ by asymmetric encryption,
but your actual communication with the server is symmetrically encrypted.

How is that? Well, it turns out that public-key cryptography is somewhere between 1,000 and 10,000
times slower than conventional cryptography. So in most use cases, we use asymmetric encryption to
come up with a shared secret key, and then use that key to symmetrically encrypt the rest of our
communication.

- How SSL works

  - There's an asymmetry in that
    - the server doesn't care about the client's identity, but the client does, and needs to confirm
      the server's credentials via a trusted third party
    - the server pays for that trusted third party (a certification authority
  - Handshake http://cloudflare.com/learning/ssl/what-happens-in-a-tls-handshake/
    - **Client** sends hello + random `Rc`
    - **Server** sends hello + cert(`S`, `s`) + random `Rs`
    - **Client** verifies cert, sends random premaster secret `Rp`, encrypted with `S` (Server
      public key) from cert
    - **Server** decrypts premaster secret using `s` (Server secret key)
    - Both **Client** and **Server** derive a symmetric key `k` using `hash(Rc + Rs + Rp)`
    - All subsequent communication is symmetrically encrypted using `k`

## <span></span> Signatures

A **digital signature** is a code that is uniquely derived from the signer's private key plus the
message being signed. It looks random and can't be generated in any other way. If Bob signs a
message, and Alice (or anyone else) knows his **public key**, they can verify the message's
**authenticity** (that Bob is the one who signed it) and its **integrity** (that it wasn't
tampered with in transit).
